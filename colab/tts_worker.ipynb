{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS Worker - Chatterbox + Higgs Audio V2\n",
    "**Purpose**: Run production-quality TTS engines on free Colab GPU\n",
    "\n",
    "**Engines**:\n",
    "- **Chatterbox** (Tier 2): Emotion exaggeration, 89/100\n",
    "- **Higgs Audio V2** (Tier 3): Ultimate quality, 92/100\n",
    "\n",
    "**Output**: HTTP API via ngrok for remote access from local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install Chatterbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chatterbox-tts\n",
    "print(\"âœ… Chatterbox installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Install Higgs Audio V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/boson-ai/higgs-audio.git\n",
    "%cd higgs-audio\n",
    "!pip install -r requirements.txt\n",
    "!pip install -e .\n",
    "%cd ..\n",
    "print(\"âœ… Higgs Audio V2 installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load Models (This takes ~2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from chatterbox.tts import ChatterboxTTS\n",
    "from boson_multimodal.serve.serve_engine import HiggsAudioServeEngine\n",
    "from boson_multimodal.data_types import ChatMLSample, Message\n",
    "\n",
    "# Load Chatterbox\n",
    "print(\"Loading Chatterbox...\")\n",
    "chatterbox = ChatterboxTTS.from_pretrained(device=\"cuda\")\n",
    "print(f\"âœ… Chatterbox loaded (SR: {chatterbox.sr}Hz)\")\n",
    "\n",
    "# Load Higgs\n",
    "print(\"\\nLoading Higgs Audio V2...\")\n",
    "higgs = HiggsAudioServeEngine(\n",
    "    \"bosonai/higgs-audio-v2-generation-3B-base\",\n",
    "    \"bosonai/higgs-audio-v2-tokenizer\",\n",
    "    device=\"cuda\"\n",
    ")\n",
    "print(\"âœ… Higgs Audio V2 loaded\")\n",
    "\n",
    "print(\"\\nðŸš€ Both models ready for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Test Chatterbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic generation\n",
    "test_text = \"In a world where true crime narratives captivate millions, one story stands above the rest.\"\n",
    "\n",
    "print(\"Generating with Chatterbox...\")\n",
    "wav = chatterbox.generate(test_text)\n",
    "torchaudio.save(\"test_chatterbox_neutral.wav\", wav, chatterbox.sr)\n",
    "print(\"âœ… Saved: test_chatterbox_neutral.wav\")\n",
    "\n",
    "# Test emotion exaggeration\n",
    "print(\"\\nTesting emotion exaggeration...\")\n",
    "wav_dramatic = chatterbox.generate(test_text, exaggeration=0.8, cfg_weight=0.3)\n",
    "torchaudio.save(\"test_chatterbox_dramatic.wav\", wav_dramatic, chatterbox.sr)\n",
    "print(\"âœ… Saved: test_chatterbox_dramatic.wav\")\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "print(\"\\nNeutral:\")\n",
    "display(Audio(\"test_chatterbox_neutral.wav\"))\n",
    "print(\"\\nDramatic (exaggeration=0.8):\")\n",
    "display(Audio(\"test_chatterbox_dramatic.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Test Higgs Audio V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"Generate audio following instruction.\\n\\n<|scene_desc_start|>\\n\"\n",
    "    \"Audio is recorded from a quiet room.\\n<|scene_desc_end|>\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    Message(role=\"system\", content=system_prompt),\n",
    "    Message(role=\"user\", content=test_text),\n",
    "]\n",
    "\n",
    "print(\"Generating with Higgs Audio V2...\")\n",
    "output = higgs.generate(\n",
    "    chat_ml_sample=ChatMLSample(messages=messages),\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.3,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    stop_strings=[\"<|end_of_text|>\", \"<|eot_id|>\"],\n",
    ")\n",
    "\n",
    "torchaudio.save(\n",
    "    \"test_higgs.wav\",\n",
    "    torch.from_numpy(output.audio)[None, :],\n",
    "    output.sampling_rate\n",
    ")\n",
    "print(\"âœ… Saved: test_higgs.wav\")\n",
    "\n",
    "print(\"\\nHiggs Audio V2:\")\n",
    "display(Audio(\"test_higgs.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Create Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\"status\": \"healthy\", \"engines\": [\"chatterbox\", \"higgs\"]})\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def generate():\n",
    "    data = request.json\n",
    "    text = data['text']\n",
    "    engine = data.get('engine', 'chatterbox')\n",
    "    \n",
    "    # Generate hash for caching\n",
    "    content_hash = hashlib.sha256(text.encode()).hexdigest()[:16]\n",
    "    output_path = f\"/tmp/tts_{engine}_{content_hash}.wav\"\n",
    "    \n",
    "    # Check cache\n",
    "    if os.path.exists(output_path):\n",
    "        return send_file(output_path, mimetype=\"audio/wav\")\n",
    "    \n",
    "    # Generate\n",
    "    if engine == 'chatterbox':\n",
    "        wav = chatterbox.generate(\n",
    "            text,\n",
    "            exaggeration=data.get('exaggeration', 0.5),\n",
    "            cfg_weight=data.get('cfg_weight', 0.5)\n",
    "        )\n",
    "        torchaudio.save(output_path, wav, chatterbox.sr)\n",
    "    \n",
    "    elif engine == 'higgs':\n",
    "        messages = [\n",
    "            Message(role=\"system\", content=system_prompt),\n",
    "            Message(role=\"user\", content=text),\n",
    "        ]\n",
    "        output = higgs.generate(\n",
    "            chat_ml_sample=ChatMLSample(messages=messages),\n",
    "            max_new_tokens=1024,\n",
    "            temperature=data.get('temperature', 0.3),\n",
    "            top_p=data.get('top_p', 0.95),\n",
    "            stop_strings=[\"<|end_of_text|>\", \"<|eot_id|>\"],\n",
    "        )\n",
    "        torchaudio.save(\n",
    "            output_path,\n",
    "            torch.from_numpy(output.audio)[None, :],\n",
    "            output.sampling_rate\n",
    "        )\n",
    "    \n",
    "    return send_file(output_path, mimetype=\"audio/wav\")\n",
    "\n",
    "print(\"âœ… Flask API configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Start ngrok Tunnel & Run Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask-ngrok pyngrok\n",
    "\n",
    "from pyngrok import ngrok\n",
    "import threading\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(5000)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ðŸš€ TTS WORKER READY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Public URL: {public_url}\")\n",
    "print(f\"\\nTest with:\")\n",
    "print(f\"curl -X POST {public_url}/generate \\\\\")\n",
    "print(f\"  -H 'Content-Type: application/json' \\\\\")\n",
    "print(f\"  -d '{{\\\"text\\\": \\\"Hello world\\\", \\\"engine\\\": \\\"chatterbox\\\"}}' \\\\\")\n",
    "print(f\"  --output test.wav\")\n",
    "print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "# Run Flask in background\n",
    "threading.Thread(target=app.run, kwargs={\"port\": 5000, \"use_reloader\": False}).start()\n",
    "\n",
    "print(\"Server running... Keep this cell alive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage from Local Machine\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# Copy the public URL from Cell 7\n",
    "WORKER_URL = \"https://xxxx-xx-xxx-xxx-xx.ngrok-free.app\"\n",
    "\n",
    "# Generate with Chatterbox\n",
    "response = requests.post(f\"{WORKER_URL}/generate\", json={\n",
    "    \"text\": \"Your narration text here\",\n",
    "    \"engine\": \"chatterbox\",\n",
    "    \"exaggeration\": 0.7,\n",
    "    \"cfg_weight\": 0.4\n",
    "})\n",
    "\n",
    "with open(\"output.wav\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"âœ… Audio saved to output.wav\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
